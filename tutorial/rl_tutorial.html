<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Simple Reinforcement Learning &mdash; DI-drive 0.1.3 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Features" href="../features/index.html" />
    <link rel="prev" title="Simple Imitation Learning" href="il_tutorial.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> DI-drive
          </a>
              <div class="version">
                0.1.3
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../installation/index.html">Installation</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Tutorial</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="core_concepts.html">Core Concepts and Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="carla_tutorial.html">Carla tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_run.html">Auto policy running and visualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="il_tutorial.html">Simple Imitation Learning</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Simple Reinforcement Learning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="#di-drive-rl-training-using-di-engine">DI-drive RL training using DI-engine</a></li>
<li class="toctree-l3"><a class="reference internal" href="#evaluate-and-test-the-trained-model">Evaluate and test the trained model</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../features/index.html">Features</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../model_zoo/index.html">Model Zoo</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_doc/index.html">API Doc</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq/index.html">FAQ</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">DI-drive</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="index.html">Tutorial</a> &raquo;</li>
      <li>Simple Reinforcement Learning</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/tutorial/rl_tutorial.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="simple-reinforcement-learning">
<h1>Simple Reinforcement Learning<a class="headerlink" href="#simple-reinforcement-learning" title="Permalink to this headline"></a></h1>
<div class="toctree-wrapper compound">
</div>
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this headline"></a></h2>
<p>Ubuntu 16.04 system +Intel(R) Core(TM) i7-8700 CPU &#64; 3.20GHz + 32G
memory + GPU1060</p>
</section>
<section id="di-drive-rl-training-using-di-engine">
<h2>DI-drive RL training using DI-engine<a class="headerlink" href="#di-drive-rl-training-using-di-engine" title="Permalink to this headline"></a></h2>
<p>DI-drive + DI-engine make RL for Autonomous Driving very easy. We build a simple RL demo that can run
varies RL algorithm with a simple environment setting. It takes a small Bird-eye View image as NN
input, together with current speed, and directly output control signals. All the code can be found in
<code class="docutils literal notranslate"><span class="pre">demo/simple_rl</span></code>.</p>
<p>Here we show how to run the DQN demo. It follows the standard deployment of a DI-engine RL entry.
Other RL demo is written in same way.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> demo/simple_rl
python dqn_train.py
</pre></div>
</div>
<p>The config part defines the env and policy settings. Notes that you need to change the Carla server
host and port, and modify the environment nums according to yours. By default it uses 8 Carla server on
<cite>localhost</cite> with port from 9000 to 9016.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">train_config</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">exp_name</span><span class="o">=...</span><span class="p">,</span>
    <span class="n">env</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
        <span class="o">...</span>
    <span class="p">),</span>
    <span class="n">server</span><span class="o">=</span><span class="p">[</span>
        <span class="nb">dict</span><span class="p">(</span><span class="n">carla_host</span><span class="o">=</span><span class="s1">&#39;localhost&#39;</span><span class="p">,</span> <span class="n">carla_ports</span><span class="o">=</span><span class="p">[</span><span class="mi">9000</span><span class="p">,</span> <span class="mi">9016</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span>
    <span class="p">],</span>
    <span class="n">policy</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
        <span class="o">...</span>
    <span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
<p>For more details about how to tune parameters in DQN, you can see their doc. Usually
you may concern about the replay buffer size and sample num per collection.</p>
<p>When you see the information in terminal that contains the content in
the following picture, it means that you are beginning to train the
model.</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/rl_tutorial_log.png"><img alt="rl_tutorial_log" src="../_images/rl_tutorial_log.png" style="width: 800px;" /></a>
</figure>
<p>In the process of training, you can use the tensorboard as a monitor,
the default log path is in your working directory.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tensorboard --logdir<span class="o">=</span><span class="s1">&#39;./log&#39;</span>
</pre></div>
</div>
<p>After running for about 24 hours, you will get:</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/rl_tutorial_tb.png"><img alt="rl_tutorial_tb" src="../_images/rl_tutorial_tb.png" style="width: 800px;" /></a>
</figure>
</section>
<section id="evaluate-and-test-the-trained-model">
<h2>Evaluate and test the trained model<a class="headerlink" href="#evaluate-and-test-the-trained-model" title="Permalink to this headline"></a></h2>
<p>After training, you can evaluate the trained model on a benchmark suite. Simply run the following code.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python dqn_eval.py
</pre></div>
</div>
<p>You may need to change Carla server numbers and settints, change the suite you want to evaluate, and add
your pre-trained weights in policy’s config.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">eval_config</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">env</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
        <span class="n">env_num</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="o">...</span>
    <span class="p">),</span>
    <span class="n">server</span><span class="o">=</span><span class="p">[</span><span class="nb">dict</span><span class="p">(</span>
        <span class="n">carla_host</span><span class="o">=</span><span class="s1">&#39;localhost&#39;</span><span class="p">,</span>
        <span class="n">carla_ports</span><span class="o">=</span><span class="p">[</span><span class="mi">9000</span><span class="p">,</span> <span class="mi">9010</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
    <span class="p">)],</span>
    <span class="n">policy</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
        <span class="n">cuda</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">ckpt_path</span><span class="o">=</span><span class="s1">&#39;path/to/your/model&#39;</span><span class="p">,</span>
        <span class="nb">eval</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
            <span class="n">evaluator</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                <span class="n">suite</span><span class="o">=</span><span class="s1">&#39;FullTown02-v1&#39;</span><span class="p">,</span>
                <span class="o">...</span>
            <span class="p">),</span>
        <span class="p">),</span>
        <span class="o">...</span>
    <span class="p">),</span>
    <span class="o">...</span>
<span class="p">)</span>
</pre></div>
</div>
<p>The default DQN policy can have nice probability to complete navigation in <cite>FullTown02-v2</cite>, with traffic lights
ignored.</p>
<p>Also, you can test the policy in a town route with a visualized screen. Simply run the following code.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python dqn_test.py
</pre></div>
</div>
<p>You may need to change Carla server settints, switch on/off visualization or save a replay gif/video
and add your pre-trained weights in policy’s config.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">test_config</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">env</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
        <span class="o">...</span>
        <span class="n">visualize</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
            <span class="nb">type</span><span class="o">=</span><span class="s1">&#39;birdview&#39;</span><span class="p">,</span>
            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;show&#39;</span><span class="p">],</span> <span class="c1"># or &#39;gif&#39;, &#39;video&#39;</span>
            <span class="n">save_dir</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span>
            <span class="n">frame_skip</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="c1"># avoid to be too large</span>
        <span class="p">),</span>
    <span class="p">),</span>
    <span class="n">server</span><span class="o">=</span><span class="p">[</span><span class="nb">dict</span><span class="p">(</span>
        <span class="n">carla_host</span><span class="o">=</span><span class="s1">&#39;localhost&#39;</span><span class="p">,</span>
        <span class="n">carla_ports</span><span class="o">=</span><span class="p">[</span><span class="mi">9000</span><span class="p">,</span> <span class="mi">9002</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
    <span class="p">)],</span>
    <span class="n">policy</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
        <span class="n">cuda</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">ckpt_path</span><span class="o">=</span><span class="s1">&#39;path/to/your/model&#39;</span><span class="p">,</span>
        <span class="nb">eval</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
            <span class="n">evaluator</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                <span class="n">render</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="o">...</span>
            <span class="p">),</span>
        <span class="p">),</span>
        <span class="o">...</span>
    <span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="il_tutorial.html" class="btn btn-neutral float-left" title="Simple Imitation Learning" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../features/index.html" class="btn btn-neutral float-right" title="Features" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, OpenDILab.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>